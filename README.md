# Sign-Language-Recognition-using-ML-Technologies

Sign language (SL) is the basic means by which deaf and mute people communicate with the normal people. As normal people cannot understand the sign language used by dumb people, it is difficult to understand the message conveyed by the dumb/deaf people. Gesture recognition is a technology that uses sensors to read and interpret hand movements and translate them in the form of text which can be interpreted by the normal people. 
Gestures are different movements employed in the communication process. Either the hand or the body makes gestures. Sign language uses gestures that typically use visually transmitted models. Gesture recognition is a computerassisted visual technique that makes it possible to detect and identify an object in an image or video. An application of this gesture recognition technique implies translating the sign language into the American language which can be better understood and interpreted by normal people. Recognizing sign language is a step forward in helping people who are deaf-mute. In sign language, each sign has a meaning that is attributed to it, so that it becomes easy for the people to understand and interpret. 
As there is need of a system which translate the sign language into text which is helpful for the normal people to understand. There is much need of such system to convey the message of deaf and dumb people. The current system which we generated is only based on hand gestures which will detect hand gesture and with the help of different algorithm interpret the text from the given sign. 
